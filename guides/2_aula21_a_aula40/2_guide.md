# Dia 21

## Aplica√ß√£o em Produ√ß√£o

### Cen√°rio atual

**Erro**  
No cen√°rio atual a aplica√ß√£o est√° retornando erro 500 na chamada √† API: https://alxtab.com.br/api/v1/status.
O erro se deve √° √∫ltima atualiza√ß√£o, onde o m√≥dulo de status/index.js interage com o banco de dados local.

**Verificar log na Vercel**
Acessar o Projeto >> Logs.
No log (produ√ß√£o) temos erro de conex√£o com o banco de dados (local): **_Error: connect ECONNREFUSED 127.0.0.1:5432_**

**Destrinchando ECONNREFUSED**

- **E**: Error
- **CONN**: CONNECTION
- **REFUSED**: REFUSED  
  Por tanto, Erro de conex√£o recusada.

### Banco de dados em Produ√ß√£o

- [x] ElephantSQL (gratu√≠to)
- [x] [Neon](https://neon.tech/) (gratu√≠to)
- [x] [DigitalOcean](https://www.digitalocean.com/) (pago)

#### Neon

- Auth usando GitHub
- Project Name: QWx4VGFiCg==
- Branch: production
- DabaseName: YWx4dGFiCg==
- Owner: neondb_owner
- Pegar par√¢metros de conex√£o
- Adicionar propriedade ssl: true em database.js

```javascript
ssl: process.env.NODE_ENV === "development" ? false : true,
```

- Na Vercel, configurar vari√°veis de ambiente do Banco de dados fornecidos pela Neon.

- Vercel >> Project (clone-tabnews) >> Settings >> Environment Variables >> Apenas Production [x] >> Adicionar Vari√°veis >> Save.

- Em Demployments, fazer redeploy para aplica√ß√£o pegar as vari√°veis de ambiente.

#### DigitalOcean

- Auth usando GitHub
- Project Name: QWx4VGFiCg==
- Branch: production
- DabaseName: YWx4dGFiCg==
- Necess√°rio adiconar forma de pagamento.

  ### Passos

  1. Deploy in database
  2. No menu database >> Postgres 16
  3. Nome da inst√¢ncia do banco de dados: production-postgres
  4. Create Database Cluster
  5. Atualizar vari√°veis de ambiente na Vercel, com base no que a Digital Ocean forneceu.

  ### Passos certificado autoassinado

  **Erro ap√≥s apontar para o servidor de banco de dados da DigitalOcean:**

  ```
  Error: self-signed certificate in certificate chain
  code: 'SELF_SIGNED_CERT_IN_CHAIN'
  ```

  **Adicionar Certificado**

  1.  Baixar certificado da DigitalOcean `ca-certificate.crt`
  2.  Simular erro no ambiente local. Atualizar .env.development com as credenciais do banco de dados da DigitalOcean

  3.  Chamar o endpoint: `http://localhost:3000/api/v1/status`

      - Exato mesmo erro de produ√ß√£o:  
        `Error: self-signed certificate in certificate chain`

  4.  Para consertar, criaremos uma function adicionando o certificado autoassinado.

      - Ajustar conte√∫do do certificado autoassinado para ficar na mesma linha.

      - Para fazer isso, basta selecionar a quebra de linha (\n) invis√≠vel de cada linha. Selecionar a primeira e ir para as pr√≥ximas usando crtl + d. Substituir toda a sele√ß√£o por `\n`. Isso far√° que todo conte√∫do v√° para mesma linha automaticamente.

      - Criar vari√°vel de ambiente `POSTGRES_CA` em `.env.development` e adicionar a linha com o certificado em base64 dentro de aspas duplas para os caracteres especiais serem interpretados.

      - Function getSSLValues()

        ```javascript
        function getSSLValues() {
          if (process.env.POSTGRES_CA) {
            return {
              ca: process.env.POSTGRES_CA,
            };
          }
          return process.env.NODE_ENV === "development" ? false : true;
        }
        ```

      - Par√¢metro SSL

        `ssl: getSSLValues(),`

      - Funcionou localmente. Agora adiconar vari√°vel de ambiente `POSTGRES_CA` com o certificado, na Vercel.

### Dicas

Comando git para restaurar altera√ß√µes: `git restore .` onde o ponto (.) indica que √© para restaurar tudo.

Ou simplemente de um arquivo `git restore .env.development `

# Dia 22

## Migrations

1. "Pro√≠bido altera√ß√µes manuais no banco de dados"
2. Criar arquivo de migra√ß√£o
3. _up_ para fazer altera√ß√µes
4. _down_ para desfazer altera√ß√µes

### Instalar depend√™ncia

`npm install node-pg-migrate@6.2.2`

**node-pg_migrate**
https://salsita.github.io/node-pg-migrate/getting-started

**node-pg_migrate cli**
https://salsita.github.io/node-pg-migrate/cli

### Adicionar spcripts no package.json

`"migration:create": "node-pg-migrate --migrate-dir infra/migrations create"`

**_--migrate-dir_**: diret√≥rio onde as migrations ser√£o criadas, op√ß√£o reduzida do comando seria `-m`

### Executar comando do script

`npm run migration:create` **_first migrate test_**

**first migrate test** √© o nome da migrate que quero criar.

Migration criada: **_clone-tabnews/migrations/1745879255524_first-magrate-test.js_**

**Entendendo o Arquivo Criado**

1. **1745879255524**: Unix timestamp do momento exato da cria√ß√£o do arquivo da migration

2. **first-magrate-test.js**: Nome do arquivo passado como argumento na execu√ß√£o do comando npm run:migration create <nome>

3. Conte√∫do que compoem um arquivo de migration

   ```javascript
   exports.shorthands = undefined;

   exports.up = (pgm) => {};

   exports.down = (pgm) => {};
   ```

   **UP**: Aplicando altera√ß√µes de forma crescente, para cima. Ex.: criar tabela `user`, altera a coluna `idade`

   **DOWN**: Apliquei uma migration, mas foi um erro aplicar ela, desfazer opera√ß√£o.

### Criar script que faz up das migrations no package.json

`"migration:up": "node-pg-migrate -m infra/migrations up"`

**Apresentou erro de credenciais, seguiremos os passos abixo para corrigir**

1. Instalar dotenv para auxiliar o m√≥dulo **node-pg-migrate**
   `npm install dotenv@16.4.4`

2. No comando de **UP** adicionar .envPath .env.development
   `"migration:up": "node-pg-migrate --migrate-dir infra/migrations --envPath .env.development up"`

3. Em `.env.development`, adiconar vari√°vel `DATBASE_URL` (connection string)

**Exemplo connection string:** protocolo://user:password@host:port/database

```
Protocolo: postgres
user: local_user
password: local_password
host: localhost
port: 5432
database: local_db
```

**Connection string:**
`postgres://local_user:local_password@localhost:5432/local_db`

3. Executar migration
   `npm run migration:up`

## Migrations parte 2

**Dry Run**: Executar as migrations, sem executar de verdade, de "metira". S√≥ para ver o que seria executado se tivesse executado de "verdade" (GET) /migrations

**Live Run**: Execu√ß√£o das migration de verdade (POST) /migrations

### Criando testes de integra√ß√£o e endpoint /migrations

1.  Dentro da pasta test/integration, criar `migrations/get.test.js`
2.  Em **migrations/get.test.js**, adicionar chamada ao endpoint /migrations
    `http://localhost:3000/api/v1/migrations`
3.  A primeira vers√£o do teste ficar√° conforme abaixo:

    ```javascript
    test("GET to /api/v1/migrations should return 200", async () => {
      const response = await fetch("http://localhost:3000/api/v1/migrations");
      expect(response.status).toBe(200);
    });
    ```

4.  Neste momento, os testes dever√£o estar retornando 404. Agora vamos implementar o endpoint /migrations.

5.  Em **pages/api/v1**, criar api para migrations `/migrations/index.js`

6.  Faremos o `export default` j√° na assinatura da function

    ```javascript
    export default async function migrations(request, response) {
      response.status(200).json({});
    }
    ```

7.  Agora os testes dever√£o retornar sucesso!

### Implementa√ß√£o migrations/index.js

- Documenta√ß√£o Programmatic API: https://salsita.github.io/node-pg-migrate/api

**Vers√£o 1, que ser√° refatorada no dia 24**

Quando o m√©todo for GET, a execu√ß√£o das migrations ser√£o no modo dryRun.
Quando POST, ser√£o executadas de verdade.

```javascript
import migrationRunner from "node-pg-migrate";
import { join } from "node:path";

export default async function migrations(request, response) {
  if (request.method === "GET") {
    const migrations = await migrationRunner({
      databaseUrl: process.env.DATABASE_URL,
      dryRun: true,
      dir: join("infra", "migrations"),
      direction: "up",
      verbose: true,
      migrationsTable: "pgmigrations",
    });
    return response.status(200).json(migrations);
  }

  if (request.method === "POST") {
    const migrations = await migrationRunner({
      databaseUrl: process.env.DATABASE_URL,
      dryRun: false,
      dir: join("infra", "migrations"),
      direction: "up",
      verbose: true,
      migrationsTable: "pgmigrations",
    });
    return response.status(200).json(migrations);
  }

  return response.status(405).end();
}
```

### Implementa√ß√£o test de integra√ß√£o

**Vers√£o 1, que ser√° refatorada no dia 24**

```javascript
test("POST to /api/v1/migrations should return 200", async () => {
  const response = await fetch("http://localhost:3000/api/v1/migrations", {
    method: "POST",
  });
  expect(response.status).toBe(200);

  const responseBody = await response.json();

  console.log(responseBody);
  expect(Array.isArray(responseBody)).toBe(true);
});
```

#### Dicas

- Execu√ß√£o espec√≠fica dos testes. Com o comando abaixo, ser√° executado apenas testes dentro de /migrations
  `npm run test:watch -- migrations`

- Dexiando a execu√ß√£o ainda mais espec√≠fica, agora para executar apenas o test de post:
  `npm run test:watch -- migrations.post` (migraions.pos √© uma Regex)

# Dia 24

### Tornando testes Jest serial (sequencial)

1. No package.json, adicionar o par√¢metro `runInBand` nos comandos jest

   `jest --runInBand`  
   `jest --watchAll --runInBand`

### Limpando base de dados para execu√ß√£o dos testes

1. Limpar state do banco de dados.
2. No test de get /migrations, importar dabase.js para executar a query de limpeza do banco de dados.

   > Tem uma quest√£o. A vers√£o do Jest que estamos usando n√£o suporta **_import_** ainda. Erro: **_SyntaxError: Cannot use import statement outside a module_**

   > Dessa forma, vamos criar um arquivo na raiz do projeto chmado `jest.config.js` onde o NextJS dar√° o super poder de import ao Jest

   > Documenta√ß√£o Jest com Next.js: https://nextjs.org/docs/app/guides/testing/jest

   **jest.config.js**

   ```javascript
   const dotenv = require("dotenv");
   dotenv.config({
     path: ".env.development",
   });
   const nextJest = require("next/jest");

   const createJestConfig = nextJest({
     dir: ".",
   });
   const jestConfig = createJestConfig({
     moduleDirectories: ["node_modules", "<rootDir>"],
   });

   module.exports = jestConfig;
   ```

3. No m√≥dulo de `migrations/get.test.js`, agora podemos importar `infra/database.js`

4. Em `migrations/get.test.js` criar function cleanDatabase

   ```javascript
   async function cleanDatabase() {
     await database.query("DROP schema public cascade; create schema public");
   }
   ```

5. Usar a function `beforeAll()` do Jest para executar a function `cleanDatbase()`
   `beforeAll(cleanDatabase);`

6. Fazer o mesmo processo no teste de post, incluindo import, function cleanDabase() e beforeAll()

   ```javascript
   import database from "infra/database.js";

   beforeAll(cleanDatabase);

   async function cleanDatabase() {
     await database.query("DROP schema public cascade; create schema public");
   }
   ```

## Refatorando c√≥digo e testes

#### C√≥digo Concreto /migrations

1. Na function migrations definimos um spread (...defaultMigrationsOptions) definindo as propriedades de como e onde est√£o as migrations a serem executadas.

2. De acordo com o m√©todo de requisi√ß√£o GET ou POST, definiremos se as migrations ser√£o executadas (POST) e `dryRun: false` ou apenas validadas (GET) `dryRun: true`

3. Qualquer chamada ao `/migrations` que n√£o seja usando os m√©todo HTTP GET ou POST, dever√° retornar status code 405, sem nenhum dado no corpo da requisi√ß√£o `.end()`

```javascript
import migrationRunner from "node-pg-migrate";
import { join } from "node:path";

export default async function migrations(request, response) {
  const defaultMigrationsOptions = {
    databaseUrl: process.env.DATABASE_URL,
    dryRun: true,
    dir: join("infra", "migrations"),
    direction: "up",
    verbose: true,
    migrationsTable: "pgmigrations",
  };

  if (request.method === "GET") {
    const pendingMigrations = await migrationRunner(defaultMigrationsOptions);
    return response.status(200).json(pendingMigrations);
  }

  if (request.method === "POST") {
    const migratedMigrations = await migrationRunner({
      ...defaultMigrationsOptions,
      dryRun: false,
    });

    if (migratedMigrations.length > 0) {
      return response.status(201).json(migratedMigrations);
    }
    return response.status(200).json(migratedMigrations);
  }

  return response.status(405).end();
}
```

#### Teste /migrations POST

1. Limpa a base de dados, excluindo o schema publica em cascata (cascade), pois existem v√°rias depend√™ncias do schema public.

2. Em seguinda, na mesma query, recriamos o schema public, deixando a base de dados sempre limpa para executar os testes.

3. Na primeira execu√ß√£o de POST, esperamos que haja migrations pendentes para serem executadas (tamanho do array maior que zero) e response `[{path: 'infra/migrations/4154646464..', name: '4154646464_test-migrations', timestamp: 4154646464}]`, retornando status code 201. Executando novamente, esperamos que n√£o haja mais migrations pendentes a serem executadas (tamanho do array seja 0) e response `[]`, retorando status code 200.

```javascript
import database from "infra/database.js";

beforeAll(cleanDatabase);

async function cleanDatabase() {
  await database.query("DROP schema public cascade; create schema public");
}

test("POST to /api/v1/migrations should return 200", async () => {
  const response1 = await fetch("http://localhost:3000/api/v1/migrations", {
    method: "POST",
  });
  expect(response1.status).toBe(201);

  const response1Body = await response1.json();

  expect(Array.isArray(response1Body)).toBe(true);
  expect(response1Body.length).toBeGreaterThan(0);

  const response2 = await fetch("http://localhost:3000/api/v1/migrations", {
    method: "POST",
  });
  expect(response2.status).toBe(200);

  const response2Body = await response2.json();

  expect(Array.isArray(response2Body)).toBe(true);
  expect(response2Body.length).toBe(0);
});
```

#### Dicas

- Operardor spread **...** (espalhar) `...defaultMigrationsOptions` (...). Ir√° expalhar dentro de {} todas as propriedades que est√£o em **defaultMigrationsOptions**

```javascript
const defaultMigrationsOptions = {
  databaseUrl: process.env.DATABASE_URL,
  dryRun: true,
  dir: join("infra", "migrations"),
  direction: "up",
  verbose: true,
  migrationsTable: "pgmigrations",
};
```

```javascript
const migrations = await migrationRunner({
  ...defaultMigrationsOptions,
});
```

- Usando o operador spread, conseguimos sobrescrever qualquer propriedade dentro do objeto, por exemplo `dryRun: false`:

```javascript
const migrations = await migrationRunner({
  ...defaultMigrationsOptions,
  dryRun: false,
});
```

# Dia 25

### Iniciando com uma problem√°tica

- No momento do projeto, nosso arquivo `.env.development` n√£o consegue fazer interpola√ß√£o de vari√°vies de ambiente, por exemplo, $POSTGRES_USER.

- Isso seria necess√°rio para diminuirmos a duplica√ß√£o dos valores das vari√°veis, que tamb√©m utilizamos em DATABASE_URL (connection string)

Forma atual do `.env.development`:

```yaml
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=local_user
POSTGRES_DB=local_db
POSTGRES_PASSWORD=local_password
DATABASE_URL=postgres://local_user:local_password@localhost:5432/local_db
```

- Para resolvermos isso, iniciamos instalando a depend√™ncia `npm install dotenv-expand@11.0.6`, que dar√° esses poderes ao arquivo `.env.development`

- Ajustando `.env.development`

```yaml
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=local_user
POSTGRES_DB=local_db
POSTGRES_PASSWORD=local_password
DATABASE_URL=postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@$POSTGRES_HOST:$POSTGRES_PORT/$POSTGRES_DB
```

- para teste, podemos executar os scripts de UP das migrations, que depende da vari√°vel **DATABASE_URL** `npm run migration:up`

### Refatatorando `database.js` para retornar uma nova inst√¢ncia do banco de dados

1. Criar function `getNewClient()` e adicionar a ela a l√≥gica de abrir conex√£o com banco de dados.

```javascript
async function getNewClient() {
  const client = new Client({
    host: process.env.POSTGRES_HOST,
    port: process.env.POSTGRES_PORT,
    user: process.env.POSTGRES_USER,
    database: process.env.POSTGRES_DB,
    password: process.env.POSTGRES_PASSWORD,
    ssl: getSSLValues(),
  });

  await client.connect();
  return client;
}
```

2. Na function `query(objectQuery)` usar a function `getNewClient()` para abrir conex√£o com o banco de dados `client = await getNewClient();`

3. Fazer o export das functions do m√≥dulo `database.js`

```javascript
export default {
  query,
  getNewClient,
};
```

4. O m√≥dulo completo fica dessa forma agora:

```javascript
import { Client } from "pg";

async function query(queryObject) {
  let client;
  try {
    client = await getNewClient();
    const result = await client.query(queryObject);
    return result;
  } catch (error) {
    console.error(error);
    throw error;
  } finally {
    await client.end();
  }
}

async function getNewClient() {
  const client = new Client({
    host: process.env.POSTGRES_HOST,
    port: process.env.POSTGRES_PORT,
    user: process.env.POSTGRES_USER,
    database: process.env.POSTGRES_DB,
    password: process.env.POSTGRES_PASSWORD,
    ssl: getSSLValues(),
  });

  await client.connect();
  return client;
}

export default {
  query,
  getNewClient,
};

function getSSLValues() {
  if (process.env.POSTGRES_CA) {
    return {
      ca: process.env.POSTGRES_CA,
    };
  }

  return process.env.NODE_ENV === "production" ? true : false;
}
```

### Agora no /migrations/index.js, podemos importa database.js e usar o `getNewClient()`

1. Substituir `databaseUrl: process.env.DATABASE_URL,` pelo novo m√©todo criado `getNewClient()`

2. Declarar vari√°vel dbClient:  
   `const dbClient = await database.getNewClient();`

3. Utilizar a vari√°vel `dbClient` para compor o objeto `defaultMigrationsOptions`

```javascript
const defaultMigrationsOptions = {
dbClient: dbClient,
dryRun: true,
...
}
```

4. Pelo fato de assumirmos a responsabilidade de abrir a conex√£o com o banco de dados **(dbClient)**, precisamos implementar o fechamento da conex√£o para n√£o cair no erro: **_Another migration is already running_**.

Tanto na verifica√ß√£o de ser GET quanto POST, ap√≥s a execu√ß√£o da fun√ß√£o migrationRunner, devemos adicionar o fechamento da conex√£o `await dbClient.end();`

**Exemplo:**

```javascript
if (request.method === "GET") {
    const pendingMigrations = await migrationRunner(defaultMigrationsOptions);
    await dbClient.end(); // aqui
    ...
  }

  if (request.method === "POST") {
    const migratedMigrations = await migrationRunner({
      ...defaultMigrationsOptions,
      dryRun: false,
    });
    await dbClient.end(); // aqui
    ...
  }
```

### /migration/index.js completo

```javascript
import migrationRunner from "node-pg-migrate";
import { join } from "node:path";
import database from "infra/database.js";

export default async function migrations(request, response) {
  const dbClient = await database.getNewClient();

  const defaultMigrationsOptions = {
    dbClient: dbClient,
    dryRun: true,
    dir: join("infra", "migrations"),
    direction: "up",
    verbose: true,
    migrationsTable: "pgmigrations",
  };

  if (request.method === "GET") {
    const pendingMigrations = await migrationRunner(defaultMigrationsOptions);
    await dbClient.end();
    return response.status(200).json(pendingMigrations);
  }

  if (request.method === "POST") {
    const migratedMigrations = await migrationRunner({
      ...defaultMigrationsOptions,
      dryRun: false,
    });
    await dbClient.end();
    if (migratedMigrations.length > 0) {
      return response.status(201).json(migratedMigrations);
    }
    return response.status(200).json(migratedMigrations);
  }

  return response.status(405).end();
}
```

### database.js completo

```javascript
import { Client } from "pg";

async function query(queryObject) {
  let client;
  try {
    client = await getNewClient();
    const result = await client.query(queryObject);
    return result;
  } catch (error) {
    console.error(error);
    throw error;
  } finally {
    await client.end();
  }
}

async function getNewClient() {
  const client = new Client({
    host: process.env.POSTGRES_HOST,
    port: process.env.POSTGRES_PORT,
    user: process.env.POSTGRES_USER,
    database: process.env.POSTGRES_DB,
    password: process.env.POSTGRES_PASSWORD,
    ssl: getSSLValues(),
  });

  await client.connect();
  return client;
}

export default {
  query,
  getNewClient,
};

function getSSLValues() {
  if (process.env.POSTGRES_CA) {
    return {
      ca: process.env.POSTGRES_CA,
    };
  }

  return process.env.NODE_ENV === "production" ? true : false;
}
```

# Dia 26

### Branches Git

- 3¬∫ N√≠vel de exemplo de compreens√£o

![alt text](images/git_branches_head.png)

### Criando banco de dados para Homologa√ß√£o.

1. Entrar onde o banco de dados est√° hospedado: https://console.neon.tech/

#### Via Project Dasboard

1. Em `Project` > `Dashboard`;
2. Clique em `Connect` > No modal Aberto, clique no menu de sele√ß√£o `Database`, e selecione `create new database`
3. Database name: `staging`  
   Obs.: Por limita√ß√µes do plano gratu√≠to, n√£o podemos criar novo projeto, ent√£o optou-se por criar novo banco de dados.

#### Via Project branch

1. Em `Branch` > `Overview`
2. Logo abaixo das informa√ß√µes sobre a branch, h√° um menu com tr√™s abas: Computes|Roles & Database|Child branches;
3. Clique em Roles & Database, e depois em Add database.
4. Database name: `staging`  
   Obs.: Por limita√ß√µes do plano gratu√≠to, n√£o podemos criar novo projeto, ent√£o optou-se por criar novo banco de dados.

### Atualizando Vercel, ambiente `preview`

1. Vercel > Projects > clone-tabnews > settings > environment variables > `adicionar vari√°veis` copiadas do novo Database criado na Neon.

### Criando nova branch no reposit√≥rio clone-tabnews

`fix/migrations-endpoint`  
Nesta branch trabalharemos a quest√£o de n√£o fechar as conex√µes com o banco de dados quado s√£o realizadas requisi√ß√µes para o endpoint `/migrations` com m√©todos `HTTP` diferentes de `GET` e `POST`.

### Replicando e corrigindo o bug do enpoint /migrations

> **Cen√°rio atual:** ao realizar requisi√ß√µes ao endpoint `/migrations` usando m√©todos HTTP diferentes de GET e POST, est√£o abrindo conex√µes com o banco de dados e n√£o est√£o fechando.

#### Solu√ß√£o

1. Verificar quais s√£o os m√©todos HTTP vindos da requisi√ß√£o. Se for diferente dos m√©todos permitidos (GET e POST), retornar status code 405. E nisso, nem entrar no passo de abrir conex√£o com o banco de dados.

```javascript
const allowedMethods = ["GET", "POST"];
if (!allowedMethods.includes(request.method)) {
  return response.status(405).json({
    error: `Method ${request.method} not allowed`,
  });
}
```

2. Retirar a responsabilidade dos m√©todos `GET` e `POST` de fechar a conex√£o com o banco de dados e atribuir a um bloco `finally`

**Portanto, neste momento do curso, o controller migrations/index.js est√° conforme abaixo. Logo ser√° refatorado, separando as responsabilidades em seus devidos m√≥dulos:**

```javascript
import migrationRunner from "node-pg-migrate";
import { join } from "node:path";
import database from "infra/database.js";

export default async function migrations(request, response) {
  const allowedMethods = ["GET", "POST"];
  if (!allowedMethods.includes(request.method)) {
    return response.status(405).json({
      error: `Method ${request.method} not allowed`,
    });
  }
  let dbClient;
  try {
    dbClient = await database.getNewClient();

    const defaultMigrationsOptions = {
      dbClient: dbClient,
      dryRun: true,
      dir: join("infra", "migrations"),
      direction: "up",
      verbose: true,
      migrationsTable: "pgmigrations",
    };

    if (request.method === "GET") {
      const pendingMigrations = await migrationRunner(defaultMigrationsOptions);
      return response.status(200).json(pendingMigrations);
    }

    if (request.method === "POST") {
      const migratedMigrations = await migrationRunner({
        ...defaultMigrationsOptions,
        dryRun: false,
      });
      if (migratedMigrations.length > 0) {
        return response.status(201).json(migratedMigrations);
      }
      return response.status(200).json(migratedMigrations);
    }
  } catch (error) {
    console.error(error);
    throw error;
  } finally {
    await dbClient.end();
  }
}
```

#### Dicas

**Deixar branch rastre√°vel local/origin**

`git push --set-upstream origin fix/migration-endpoint`

Esse comando ajuda a n√£o precisar ficar colocando sempre o `origin` nos comandos de push, por exemplo, `git push origin fix/migration-endpoint`. Ap√≥s o comando `--set-upstream origin`, basta usar apenas git push e as altera√ß√µes ser√£o empurradas para o reposit√≥rio origin (remoto)

**Deploy manual na Vercel**

1. Acesse a aba Deployments.
2. Clique no bot√£o de [...] para abrir as op√ß√µes.
3. Selecione Create Deployment.
4. Selecionar a branch, no caso `fix-migration-endpoint`
5. O ambiente `preview` ser√° selecionado automaticamente.

**Deployment Protection**

- https://vercel.com/alx0594s-projects/clone-tabnews/settings/deployment-protection

- Deployment protection √© uma prote√ß√£o implementada pela Vercel que grante que os visitantes destejam conectados ao Vercel e sejma membros da equipe.

- No promeiro momento, vamos desabilitar essa op√ß√£o, assim, conseguiremos realizar o `curl` contra o endpoint `https://clone-tabnews-git-fix-migration-endpoint-alx0594s-projects.vercel.app/api/v1/status` normalmente via terminal.

**Tratamento do response como JSON no terminal usando Python**

- No comando `curl -s https://clone-tabnews-git-fix-migration-endpoint-alx0594s-projects.vercel.app/api/v1/status` adicionar um pipe (|) no final seguido do comando `python -m json.tool`

- Comando completo:
  `curl -s https://clone-tabnews-git-fix-migration-endpoint-alx0594s-projects.vercel.app/api/v1/status | python -m json.tool`

- No linux, usar **python3**

**Tratamento do response como JSON no terminal usando JQ**
`curl -s https://clone-tabnews-git-fix-migration-endpoint-alx0594s-projects.vercel.app/api/v1/status | jq`

# Dia 27

### Merge

- O git possui duas formas de merge, o `Fast-Forward` e o `3-Way Merge`

- Target Branch (Branch Alvo) do merge e Font Branch (Branch Fonte) com as altera√ß√µes para realizar o marge.

- Dessa forma, a branch `main` (que estamos atualmente) √© nossa target branch (HEAD) e a branch fix-migration-endpoint √© nossa font branch. Logo, para fazer o merge, basta executar: `git merge fix-migration-endpoint`

![alt text](images/merge_local_fast_forward.png)

### Ajustando banco de dados na Neon

- A Neon tamb√©m ser√° nosso banco de dados para produ√ß√£o, logo, precisamos ajustar o que era da DigitalOcean na Vercel para apontar para Neon.

1. Na Neon, alterar database name de alxtab para production.
2. Atualizar vari√°veis de ambiente de production na Vercel.

#### Dicas

- Como deletar branches?
  `git branch -d <nome-da-branch>`

  - Quando usamos o `-d` o git avalia se o conte√∫do da branch que ser√° deletada foi mesclada com a branch principal. Caso n√£o tenha sido, a dele√ß√£o n√£o √© realizada.

  - Caso queira for√ßar a dele√ß√£o, basta usar o `-D` mai√∫sculo.

  - **Importante**, sempre que uma branch √© deletada, √© retornado o hash do √∫ltimo commit da mesma, por exemplo (07d175c). Se a branch foi exclu√≠da por engano, podemos foltar o HEAD para esse commit novamente: `git checkout 07d175c`, log em seguida fazer que o mesmo aponte para uma branch: `git checkou -b fix-migration-endpoint`. Para fazer os dois comandos em um s√≥, podemos fazer: `git checkout -b fix-migration-endpoint 07d175c`

  - **Importante**, o git tem uma pol√≠tica de limpeza [Garbage Collector - git-gc](https://git-scm.com/docs/git-gc) que s√≥ deixa esses commits pendurados sem branch por 14 dias. No entando esse tempo pode ser configurado.

  - E no cen√°rio de eu n√£o ter registrado o hash do commit no momento que deletei a branch? Existe um comando no git, que registra tudo que acontece com os comando git: `git reflog` **_reference log_**

  - **Verificando log com linha do tempo**: `git log --graph`

# Dia 28

### Estrat√©gias de branch

1. Trunk-based Development
   Sempre integrar o c√≥digo na branch `main`

2. **Feature Branch**
   Para cada novo recurso ou corre√ß√£o de bug, criar e desenvolver na `feature branch` e depois fazer o merge para a branch principal. A branch `main` sempre precisa estar pronta para ir para `produ√ß√£o`.

   ![alt text](images/feature-branch.png)

3. Git Flow
   Segundo o pr√≥prio idealista do modelo Git Flow, essa n√£o √© a melhor abordagem para o atual cen√°rio de desenvolvimento, principalmente pelo fato das aplica√ß√µes serem cada vez mais desenvolvidas para web e com frequ√™ncia de atualiza√ß√£o. Segundo o pr√≥prio autor, `Git Flow` se tornou um modelo legado.

   ![alt text](images/git_workflow.png)

4. Trunk-base Development

   ![alt text](images/trunk-based-2.png)

**Usaremos `Feature Branch`**

# Dia 29

**Cen√°rio atual:** Antes de executar a aplica√ß√£o, queremos subir o banco de dados e executar as migrations.  
Para tanto, a primeira abordagem foi: `"dev": "npm run services:up && npm run migration:up && next dev"`, e acabou gerando um problema.
O comando para executar as migrations inicia a execu√ß√£o antes do banco de dados estar totalmente dispon√≠vel. Para solucionar esse apontamento, vamos criar um script js.

### Criando Script JS

1. Na pasta `infra`, criar pasta `scripts`
2. Dentro da pasta scripts, criar script `wait-for-postgres.js`
3. No `package.json`, criar execu√ß√£o do script: `"wait-for-posgres": "node infra/scripts/wait-for-postgres.js"`
4. Primeiro comando no script para testes:
   console.log("üî¥Aguardando Postgres aceitar conex√µes");
5. Execu√ß√£o: `npm run wait-for-postgres`

**Melhorando wait-for-posgres.js**

1. No infra/compose.yaml, definir qual ser√° o nome do container:
   `container_name: "postgres-dev"`
2. Para executar processos dentro de scripts JS, precisamos usar a depend√™ncia child_process. No script `wait-for-postres.js`, importar `require("node:child_process")` N√£o vamos usar import, pois esse arquivo n√£o ser√° transpilado.
3. No import, usaremos a `desestrutura√ß√£o`, trazendo o m√©todo `exec` para fora: `const { exec } = require("node:child_process");`

**O que esse script faz?**

- Ele verifica se o banco de dados Postgres est√° pronto para aceitar conex√µes, usando o comando Docker. Se ainda n√£o estiver pronto, ele espera um pouco e tenta de novo.

- **Callback**
  `exec("docker exec postgres-dev pg_isready --host localhost", handleReturn);`

  1. A fun√ß√£o exec(...) executa um comando no terminal.
  2. Esse comando vai rodar de forma ass√≠ncrona ‚Äî ou seja, ele n√£o para o c√≥digo, ele vai rodar em segundo plano.
  3. Quando o comando terminar (pode ser r√°pido ou demorar), ele chama a fun√ß√£o handleReturn com os resultados do comando.
     - Isso √© o callback: a fun√ß√£o handleReturn √© chamada quando o comando terminar.

- **Recursividade**
  Recursividade √© quando uma fun√ß√£o **chama ela mesma**.

  ```javascript
  if (stdout.search("accepting connections") === -1) {
    process.stdout.write(".");
    checkPosgres(); // Chama de novo a fun√ß√£o checkPosgres()
    return;
  }
  ```

  - Se o banco de dados **ainda n√£o est√° pronto** (a frase ‚Äúaccepting connections‚Äù n√£o apareceu), ele **chama de novo a pr√≥pria fun√ß√£o** `checkPosgres`.
  - Isso continua at√© o Postgres finalmente responder que est√° pronto.

  **Script completo**

```javascript
const { exec } = require("node:child_process");

function checkPosgres() {
  exec("docker exec postgres-dev pg_isready --host localhost", handleReturn);
  // Depois que terminar a execu√ß√£o **docker exec postgres-dev pg_isready --host localhost**, chame a fun√ß√£o de callback **handleReturn**

  function handleReturn(error, stdout, stderr) {
    // handleReturn -> Fun√ß√£o de callback
    if (stdout.search("accepting connections") === -1) {
      process.stdout.write("."); // adicionando . na sa√≠da padr√£o stdout
      checkPosgres(); // Chama de novo a fun√ß√£o checkPosgres()
      return;
    }
    console.log("\nüü¢ Postgres est√° pronto e aceitando conex√µes\n");
  }
}

process.stdout.write("\n\nüî¥ Aguardando Postgres aceitar conex√µes");
checkPosgres();
```

### Execu√ß√£o dos Testes

**Cen√°rio atual:** N√£o conseguimos executar o comando `npm test` para os testes de migra√ß√£o sem antes subir o banco de dados e executar as migrations. Iremos trabalhar na automa√ß√£o para execu√ß√£o dos testes.

1. No package.json, atualizar o comando de **test** `"test": "npm run services:up && npm run wait-for-postgres && jest --runInBand",`

   - S√≥ que neste ponto temos uma quest√£o. Tamb√©m precisamos que o servidor de aplica√ß√£o esteja em execu√ß√£o para realizarmos o `fetch`. Por conta disso, iremos instalar uma depend√™ncia de concorr√™ncia `concurrently` e posteriormente orquestrar que os testes sejam executados apenas quando o servidor da aplica√ß√£o esteja dispon√≠vel.

2. Instalar depend√™ncia de [concorr√™ncia](https://www.npmjs.com/package/concurrently): `npm install concurrently@8.2.2`

**Primeira abordagem**

```javascript
"test": "npm run services:up && npm run wait-for-postgres && concurrently -n next,jest --hide next -k -s command-jest \"next dev\" \"jest --runInBand\"",
```

Estamos executando o script de `service:up`, em seguida o script `wait-for-postres`, ou seja, subimos o banco de dados e executamos a migration. Agora o pr√≥ximo est√°gio √© executar de forma concorrente o `next` e o `jest`. Entendendo concurrently e os par√¢metros:

- `-n` nome dos servi√ßos que ser√£o executados em paralelos `next,jest` Caso esse par√¢metro n√£o seja definido, ser√° retornado [0], [1], [...] na sa√≠da dos comandos.

- `--hide` para esconder a sa√≠da do `next` pois o que importa para n√≥s √© a sa√≠da do `jest`

- `-k` kill do processo do `concurrently` para n√£o ficar prendendo o terminal.

- `-s` status de `success` de acordo com status retornado pelo jest `command-jest`

- `\"next dev\" \"jest --runInBand\"` os servi√ßos que ser√£o executados, no caso `next` e `jest`

#### Fazendo orquestrador para os testes

Decidido, a princ√≠pio, que o melhor local para ter o `orchestrator` √© na raiz da pasta tests.

2. Na pasta tests, criar m√≥dulo `orchestrator.js`

3. No testes de get status, `get.test.js` importar o m√©dulo **orchestrator.js** `import orchestrator from "tests/orchestrator.js";`

4. Instalar a depend√™ncia [async-retry](https://www.npmjs.com/package/async-retry) respons√°vel por fazer a retentativa at√© receber o retorno 200: `npm install async-retry@1.3.3`

5. Implementar o `orchestrator.js` conforme a baixo:

```javascript
import retry from "async-retry";

async function waitForAllServices() {
  await waitForWebServer();

  async function waitForWebServer() {
    return retry(fetchStatusPage, {
      retries: 100,
      maxTimeout: 1000,
    });

    async function fetchStatusPage() {
      const response = await fetch("http://localhost:3000/api/v1/status");
      const responsebody = await response.json();
    }
  }
}

export default {
  waitForAllServices,
};
```

6. Nos testes de `status` get.test.js, chamar o `orchestrator.js` antes das execu√ß√µes dos testes

```javascript
import orchestrator from "tests/orchestrator.js";

beforeAll(async () => {
  await orchestrator.waitForAllServices();
});
```

7. Nos testes de **migrations** `get.test.js` e `post.test.js` chamar o `orchestrator.js` antes das execu√ß√µes:

```javascript
import database from "infra/database.js";
import orchestrator from "tests/orchestrator.js";

beforeAll(async () => {
  await orchestrator.waitForAllServices();
  await database.query("DROP schema public cascade; create schema public");
});
```

**Para tornar os testes mais recilientes, ajustamos o timeout do jest, para n√£o ser interrompido pelo valor default de 5 segundos**

8. Em `jest.config.js`, ajustar o tempo de espera dos tests do Jest. `testTimeout: 6000, //ms`

9. No `package.json` ajustar script de `test`, removendo a execu√ß√£o do script `wait-for-postgres` Agora fica conforme abaixo:

`"test": "npm run services:up && concurrently -n next,jest --hide next -k -s command-jest \"next dev\" \"jest --runInBand\"",`

### Dicas

### Fun√ß√£o callback

Uma **fun√ß√£o de callback** √© como dizer:  
**"Quando voc√™ terminar, me chame!"**

### Sa√≠das de programas

**stdout:** Standard Output, usado para exibir a sa√≠da normal/padr√£o de um programa.

**stderr:** Standard Error, usado para sa√≠da de mensagem de erro.

### Emojis VSCode no Windows.

- Atalho: `Win` + `.`

### Docker prune

Comando docker para deletar tudo e iniciar do zero: `docker system prune -a`

**Curiosidade**
Are you sure you want to continue? [y/N]  
A letra que fica em mai√∫sca √© sempre a default caso apertemos enter.

### Exit code

**echo $?** representa o exit code do √∫ltimo processo que foi encerrado.
**code 130** `SIGINT` - Signal Interrupt - Interrup√ß√£o de Sinal. Por exemplo, interromper uma execu√ß√£o com o `control + c`.

# Dia 30

Ponto de parada: https://curso.dev/web/estabilizar-npm-test-revisao-2
